#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è·¯çº¿0ï¼šè·¯å¾„æ„ŸçŸ¥å¤šå¤´æ³¨æ„åŠ›GNN - è®­ç»ƒè„šæœ¬
ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å’Œè·¯å¾„è®°å¿†çš„GNNåœ¨å­å›¾ä¸Šè®­ç»ƒï¼Œç”¨äºå¤šè·³æ¨ç†
é›†æˆäº†èŠ‚ç‚¹è§’è‰²ç‰¹å®šå˜æ¢ã€è¾¹ç±»å‹ç‰¹å®šå¤„ç†å’Œè·¯å¾„è®°å¿†æ¨¡å—
"""

import os
import sys
import json
import argparse
import time
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import dgl
from sklearn.metrics import precision_recall_curve, auc, average_precision_score
import matplotlib.pyplot as plt
from tensorboardX import SummaryWriter  # å¯è§†åŒ–å·¥å…·
from collections import deque
from tqdm import tqdm
import networkx as nx

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from utils.graph_utils import load_graph_data

# Route0è¿‡æ‹Ÿåˆç›‘æ§ç±»
class Route0OverfittingMonitor:
    """Route0è¿‡æ‹Ÿåˆç›‘æ§å™¨ - å¤šç»´åº¦æ£€æµ‹è¿‡æ‹Ÿåˆä¿¡å·"""
    
    def __init__(self, patience=5, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        
        # å†å²è®°å½•
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []
        self.attention_entropies = []
        self.path_complexities = []
        
        # è¿‡æ‹Ÿåˆä¿¡å·
        self.overfitting_signals = {
            'loss_gap': False,
            'acc_gap': False,
            'attention_collapse': False,
            'path_complexity': False
        }
        
        self.early_stop_counter = 0
        self.best_val_loss = float('inf')
    
    def calculate_attention_entropy(self, attention_weights):
        """è®¡ç®—æ³¨æ„åŠ›æƒé‡çš„ç†µ - ä½ç†µè¡¨ç¤ºæ³¨æ„åŠ›è¿‡åº¦é›†ä¸­"""
        if len(attention_weights) == 0:
            return 0.0
        
        # å½’ä¸€åŒ–æ³¨æ„åŠ›æƒé‡
        weights = np.array(list(attention_weights.values()))
        if len(weights) == 0:
            return 0.0
        
        # è®¡ç®—æ¯æ¡è¾¹çš„å¹³å‡æ³¨æ„åŠ›
        avg_weights = []
        for edge_weights in weights:
            if len(edge_weights) > 0:
                avg_weights.append(np.mean(edge_weights))
        
        if len(avg_weights) == 0:
            return 0.0
        
        # å½’ä¸€åŒ–
        avg_weights = np.array(avg_weights)
        avg_weights = avg_weights / (np.sum(avg_weights) + 1e-8)
        
        # è®¡ç®—ç†µ
        entropy = -np.sum(avg_weights * np.log(avg_weights + 1e-8))
        return entropy
    
    def calculate_path_complexity(self, model, g, node_feats, edge_weights, question_idx):
        """è®¡ç®—è·¯å¾„å¤æ‚åº¦ - è¿‡æ‹Ÿåˆæ—¶è·¯å¾„å¯èƒ½è¿‡äºå¤æ‚"""
        try:
            # è·å–æ³¨æ„åŠ›åˆ†æ•°ï¼ˆéœ€è¦æ¨¡å‹æ”¯æŒï¼‰
            if hasattr(model, '_extract_paths'):
                # æ¨¡æ‹Ÿæ³¨æ„åŠ›åˆ†æ•°
                edge_attention_scores = {}
                edge_src, edge_dst = g.edges()
                for i in range(len(edge_src)):
                    src, dst = edge_src[i].item(), edge_dst[i].item()
                    edge_key = (src, dst)
                    edge_attention_scores[edge_key] = [np.random.random()]  # å ä½ç¬¦
                
                paths = model._extract_paths(g, edge_attention_scores, question_idx)
                
                if len(paths) > 0:
                    # è®¡ç®—å¹³å‡è·¯å¾„é•¿åº¦
                    avg_path_length = np.mean([len(path[0]) for path in paths])
                    # è®¡ç®—è·¯å¾„æƒé‡æ–¹å·®
                    path_weights = [path[1] for path in paths]
                    weight_variance = np.var(path_weights) if len(path_weights) > 1 else 0
                    
                    return avg_path_length + weight_variance
                else:
                    return 0.0
            else:
                return 0.0
        except Exception as e:
            return 0.0
    
    def update(self, train_loss, val_loss, train_acc, val_acc, 
               attention_weights=None, model=None, g=None, node_feats=None, 
               edge_weights=None, question_idx=None):
        """æ›´æ–°ç›‘æ§æŒ‡æ ‡"""
        
        # æ›´æ–°å†å²è®°å½•
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.train_accs.append(train_acc)
        self.val_accs.append(val_acc)
        
        # è®¡ç®—æ³¨æ„åŠ›ç†µ
        if attention_weights is not None:
            entropy = self.calculate_attention_entropy(attention_weights)
            self.attention_entropies.append(entropy)
        
        # è®¡ç®—è·¯å¾„å¤æ‚åº¦
        if model is not None and g is not None:
            complexity = self.calculate_path_complexity(
                model, g, node_feats, edge_weights, question_idx
            )
            self.path_complexities.append(complexity)
        
        # æ£€æµ‹è¿‡æ‹Ÿåˆä¿¡å·
        self._detect_overfitting()
        
        # æ—©åœæ£€æŸ¥
        if val_loss < self.best_val_loss - self.min_delta:
            self.best_val_loss = val_loss
            self.early_stop_counter = 0
        else:
            self.early_stop_counter += 1
    
    def _detect_overfitting(self):
        """æ£€æµ‹å„ç§è¿‡æ‹Ÿåˆä¿¡å·"""
        if len(self.train_losses) < 3:
            return
        
        # 1. æŸå¤±å·®è·æ£€æµ‹
        recent_train_loss = np.mean(self.train_losses[-3:])
        recent_val_loss = np.mean(self.val_losses[-3:])
        loss_gap = recent_val_loss - recent_train_loss
        self.overfitting_signals['loss_gap'] = loss_gap > 0.1
        
        # 2. å‡†ç¡®ç‡å·®è·æ£€æµ‹
        recent_train_acc = np.mean(self.train_accs[-3:])
        recent_val_acc = np.mean(self.val_accs[-3:])
        acc_gap = recent_train_acc - recent_val_acc
        self.overfitting_signals['acc_gap'] = acc_gap > 0.1
        
        # 3. æ³¨æ„åŠ›åå¡Œæ£€æµ‹
        if len(self.attention_entropies) >= 3:
            recent_entropy = np.mean(self.attention_entropies[-3:])
            self.overfitting_signals['attention_collapse'] = recent_entropy < 0.5
        
        # 4. è·¯å¾„å¤æ‚åº¦æ£€æµ‹
        if len(self.path_complexities) >= 3:
            recent_complexity = np.mean(self.path_complexities[-3:])
            self.overfitting_signals['path_complexity'] = recent_complexity > 5.0
    
    def should_early_stop(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ"""
        # å¦‚æœå¤šä¸ªä¿¡å·åŒæ—¶è§¦å‘ï¼Œå»ºè®®æ—©åœ
        signal_count = sum(self.overfitting_signals.values())
        return signal_count >= 2 or self.early_stop_counter >= self.patience
    
    def get_report(self):
        """ç”Ÿæˆè¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Š"""
        if len(self.train_losses) == 0:
            return "æš‚æ— æ•°æ®"
        
        report = []
        report.append("=== Route0è¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Š ===")
        
        # å½“å‰çŠ¶æ€
        if len(self.train_losses) > 0:
            report.append(f"å½“å‰è®­ç»ƒæŸå¤±: {self.train_losses[-1]:.4f}")
            report.append(f"å½“å‰éªŒè¯æŸå¤±: {self.val_losses[-1]:.4f}")
            report.append(f"æŸå¤±å·®è·: {self.val_losses[-1] - self.train_losses[-1]:.4f}")
        
        if len(self.train_accs) > 0:
            report.append(f"å½“å‰è®­ç»ƒå‡†ç¡®ç‡: {self.train_accs[-1]:.4f}")
            report.append(f"å½“å‰éªŒè¯å‡†ç¡®ç‡: {self.val_accs[-1]:.4f}")
            report.append(f"å‡†ç¡®ç‡å·®è·: {self.train_accs[-1] - self.val_accs[-1]:.4f}")
        
        # è¿‡æ‹Ÿåˆä¿¡å·
        report.append("\nè¿‡æ‹Ÿåˆä¿¡å·æ£€æµ‹:")
        for signal, triggered in self.overfitting_signals.items():
            status = "ğŸ”´ è§¦å‘" if triggered else "ğŸŸ¢ æ­£å¸¸"
            report.append(f"  {signal}: {status}")
        
        # å»ºè®®
        signal_count = sum(self.overfitting_signals.values())
        if signal_count == 0:
            report.append("\nå»ºè®®: è®­ç»ƒçŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­è®­ç»ƒ")
        elif signal_count == 1:
            report.append("\nå»ºè®®: å‡ºç°è½»å¾®è¿‡æ‹Ÿåˆä¿¡å·ï¼Œå¯†åˆ‡ç›‘æ§")
        else:
            report.append("\nå»ºè®®: å¤šä¸ªè¿‡æ‹Ÿåˆä¿¡å·è§¦å‘ï¼Œè€ƒè™‘æ—©åœæˆ–è°ƒæ•´è¶…å‚æ•°")
        
        return "\n".join(report)
    
    def plot_analysis(self, save_path=None):
        """ç»˜åˆ¶è¿‡æ‹Ÿåˆåˆ†æå›¾è¡¨"""
        if len(self.train_losses) < 2:
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Route0è¿‡æ‹Ÿåˆåˆ†æ', fontsize=16)
        
        epochs = range(len(self.train_losses))
        
        # 1. æŸå¤±å¯¹æ¯”
        axes[0, 0].plot(epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        axes[0, 0].plot(epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        axes[0, 0].set_title('æŸå¤±å¯¹æ¯”')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å‡†ç¡®ç‡å¯¹æ¯”
        axes[0, 1].plot(epochs, self.train_accs, 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
        axes[0, 1].plot(epochs, self.val_accs, 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
        axes[0, 1].set_title('å‡†ç¡®ç‡å¯¹æ¯”')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. æŸå¤±å·®è·
        if len(self.train_losses) > 0:
            loss_gaps = [v - t for v, t in zip(self.val_losses, self.train_losses)]
            axes[0, 2].plot(epochs, loss_gaps, 'g-', linewidth=2)
            axes[0, 2].axhline(y=0.1, color='r', linestyle='--', alpha=0.7, label='è¿‡æ‹Ÿåˆé˜ˆå€¼')
            axes[0, 2].set_title('éªŒè¯-è®­ç»ƒæŸå¤±å·®è·')
            axes[0, 2].set_xlabel('Epoch')
            axes[0, 2].set_ylabel('Loss Gap')
            axes[0, 2].legend()
            axes[0, 2].grid(True, alpha=0.3)
        
        # 4. å‡†ç¡®ç‡å·®è·
        if len(self.train_accs) > 0:
            acc_gaps = [t - v for t, v in zip(self.train_accs, self.val_accs)]
            axes[1, 0].plot(epochs, acc_gaps, 'orange', linewidth=2)
            axes[1, 0].axhline(y=0.1, color='r', linestyle='--', alpha=0.7, label='è¿‡æ‹Ÿåˆé˜ˆå€¼')
            axes[1, 0].set_title('è®­ç»ƒ-éªŒè¯å‡†ç¡®ç‡å·®è·')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Accuracy Gap')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        # 5. æ³¨æ„åŠ›ç†µ
        if len(self.attention_entropies) > 0:
            axes[1, 1].plot(range(len(self.attention_entropies)), self.attention_entropies, 'purple', linewidth=2)
            axes[1, 1].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='åå¡Œé˜ˆå€¼')
            axes[1, 1].set_title('æ³¨æ„åŠ›ç†µ')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Attention Entropy')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        else:
            axes[1, 1].text(0.5, 0.5, 'æš‚æ— æ³¨æ„åŠ›æ•°æ®', ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('æ³¨æ„åŠ›ç†µ')
        
        # 6. è·¯å¾„å¤æ‚åº¦
        if len(self.path_complexities) > 0:
            axes[1, 2].plot(range(len(self.path_complexities)), self.path_complexities, 'brown', linewidth=2)
            axes[1, 2].axhline(y=5.0, color='r', linestyle='--', alpha=0.7, label='å¤æ‚åº¦é˜ˆå€¼')
            axes[1, 2].set_title('è·¯å¾„å¤æ‚åº¦')
            axes[1, 2].set_xlabel('Epoch')
            axes[1, 2].set_ylabel('Path Complexity')
            axes[1, 2].legend()
            axes[1, 2].grid(True, alpha=0.3)
        else:
            axes[1, 2].text(0.5, 0.5, 'æš‚æ— è·¯å¾„æ•°æ®', ha='center', va='center', transform=axes[1, 2].transAxes)
            axes[1, 2].set_title('è·¯å¾„å¤æ‚åº¦')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"è¿‡æ‹Ÿåˆåˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        return fig

# è·¯å¾„æ„ŸçŸ¥GNNæ¨¡å‹
class PathAttentionGNN(nn.Module):
    def __init__(self, in_dim, hidden_dim, num_layers=3, num_heads=4, dropout=0.2):
        super(PathAttentionGNN, self).__init__()
        self.in_dim = in_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.num_heads = num_heads
        self.dropout = dropout
        
        # èŠ‚ç‚¹ç±»å‹ç‰¹å®šçš„å˜æ¢
        self.question_transform = nn.Linear(in_dim, hidden_dim)
        self.entity_transform = nn.Linear(in_dim, hidden_dim)
        self.context_transform = nn.Linear(in_dim, hidden_dim)
        
        # å¤šå¤´æ³¨æ„åŠ›å±‚
        self.attention_heads = nn.ModuleList([
            nn.ModuleList([
                nn.Linear(hidden_dim, hidden_dim // num_heads),  # æŸ¥è¯¢å˜æ¢
                nn.Linear(hidden_dim, hidden_dim // num_heads),  # é”®å˜æ¢
                nn.Linear(hidden_dim, hidden_dim // num_heads)   # å€¼å˜æ¢
            ]) for _ in range(num_heads)
        ])
        
        # è¾¹ç±»å‹ç‰¹å®šçš„å˜æ¢ - ä¿®æ”¹ä¸ºé€‚åº”å¤šå¤´æ³¨æ„åŠ›çš„ç»´åº¦
        head_dim = hidden_dim // num_heads
        self.edge_transforms = nn.ModuleDict({
            'answers': nn.Linear(head_dim, head_dim),
            'evidencedBy': nn.Linear(head_dim, head_dim),
            'supportsAnswer': nn.Linear(head_dim, head_dim),
            'relatedTo': nn.Linear(head_dim, head_dim),
            'default': nn.Linear(head_dim, head_dim)
        })
        
        # æ³¨æ„åŠ›è¾“å‡ºè½¬æ¢
        self.attention_output = nn.Linear(hidden_dim, hidden_dim)
        
        # è·¯å¾„è®°å¿†æ¨¡å—
        self.path_memory = nn.GRUCell(hidden_dim, hidden_dim)
        
        # è·¯å¾„é‡è¦æ€§è¯„åˆ†
        self.path_scorer = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
        
        # å±‚é—´æ®‹å·®è¿æ¥
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim) for _ in range(num_layers)
        ])
        
        # è¾“å‡ºå±‚
        self.output = nn.Linear(hidden_dim, 1)
        
        self.dropout_layer = nn.Dropout(dropout)
    
    def forward(self, g, node_feats, edge_weights=None):
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹åº”ç”¨ä¸åŒçš„è½¬æ¢
        h = torch.zeros(node_feats.size(0), self.hidden_dim, device=node_feats.device)
        
        # æ ¹æ®èŠ‚ç‚¹è§’è‰²åº”ç”¨ä¸åŒçš„å˜æ¢
        for i, ntype in enumerate(g.ndata['role']):
            if ntype == 'question':
                h[i] = self.question_transform(node_feats[i])
            elif ntype in ['evidence', 'answer']:
                h[i] = self.entity_transform(node_feats[i])
            else:  # context
                h[i] = self.context_transform(node_feats[i])
        
        # åˆå§‹åŒ–ç‰¹å¾
        h = F.relu(h)
        
        # ä¿å­˜æ‰€æœ‰èŠ‚ç‚¹çš„è·¯å¾„è®°å¿† - ä¿®å¤ï¼šä½¿ç”¨detach()é¿å…å°±åœ°æ“ä½œ
        path_memories = h.detach().clone()
        
        # ä¿å­˜æ¯å±‚çš„èŠ‚ç‚¹è¡¨ç¤ºç”¨äºæ®‹å·®è¿æ¥
        previous_h = h
        
        # è¾¹ç¼˜æ³¨æ„åŠ›åˆ†æ•°
        edge_attention_scores = {}
        
        # æ¶ˆæ¯ä¼ é€’
        for layer_idx in range(self.num_layers):
            # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
            multi_head_out = []
            
            for head_idx in range(self.num_heads):
                q_transform, k_transform, v_transform = self.attention_heads[head_idx]
                
                # è®¡ç®—æŸ¥è¯¢ã€é”®ã€å€¼
                queries = q_transform(h)
                keys = k_transform(h) 
                values = v_transform(h)
                
                # æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ (ä½¿ç”¨src-dstè¾¹ä¿¡æ¯)
                edge_src, edge_dst = g.edges()
                
                # åˆå§‹åŒ–æ¶ˆæ¯ - ä¿®æ”¹ä¸ºé€‚åº”å¤šå¤´æ³¨æ„åŠ›çš„ç»´åº¦
                head_messages = torch.zeros(h.size(0), self.hidden_dim // self.num_heads, device=h.device)
                
                # å¯¹æ¯æ¡è¾¹è®¡ç®—æ³¨æ„åŠ›
                for i in range(len(edge_src)):
                    src, dst = edge_src[i], edge_dst[i]
                    
                    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
                    attn_score = torch.sum(queries[dst] * keys[src]) / np.sqrt(self.hidden_dim // self.num_heads)
                    
                    # è·å–è¾¹ç±»å‹å¹¶åº”ç”¨ç‰¹å®šå˜æ¢
                    edge_type = g.edata['rel'][i] if 'rel' in g.edata else 'default'
                    if isinstance(edge_type, torch.Tensor):
                        edge_type = 'default'  # å¤„ç†å¼ é‡æƒ…å†µ
                    
                    # è·å–å¯¹åº”çš„è¾¹å˜æ¢
                    if edge_type in self.edge_transforms:
                        transform = self.edge_transforms[edge_type]
                    else:
                        transform = self.edge_transforms['default']
                    
                    # åº”ç”¨æ³¨æ„åŠ›å’Œè¾¹æƒé‡
                    edge_weight = edge_weights[i] if edge_weights is not None else 1.0
                    attn_weight = F.softmax(attn_score, dim=0) * edge_weight
                    
                    # ä¿å­˜æ³¨æ„åŠ›åˆ†æ•°ç”¨äºè·¯å¾„åˆ†æ
                    edge_key = (src.item(), dst.item())
                    if edge_key not in edge_attention_scores:
                        edge_attention_scores[edge_key] = []
                    edge_attention_scores[edge_key].append(attn_weight.item())
                    
                    # è®¡ç®—æ¶ˆæ¯
                    message = transform(values[src]) * attn_weight
                    head_messages[dst] += message
                
                multi_head_out.append(head_messages)
            
            # åˆå¹¶å¤šå¤´è¾“å‡º
            if len(multi_head_out) > 0:
                combined_messages = torch.cat(multi_head_out, dim=-1)
            else:
                combined_messages = torch.zeros(h.size(0), self.hidden_dim, device=h.device)
            
            # ä¿®å¤ï¼šé¿å…å°±åœ°æ“ä½œï¼Œåˆ›å»ºæ–°çš„è·¯å¾„è®°å¿†å¼ é‡
            new_path_memories = torch.zeros_like(path_memories)
            for i in range(len(h)):
                # ç¡®ä¿è¾“å…¥ç»´åº¦åŒ¹é…
                if combined_messages.size(-1) == self.hidden_dim:
                    new_path_memories[i] = self.path_memory(combined_messages[i], path_memories[i])
                else:
                    # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨çº¿æ€§å˜æ¢è°ƒæ•´
                    adjusted_input = self.attention_output(combined_messages[i])
                    new_path_memories[i] = self.path_memory(adjusted_input, path_memories[i])
            
            # æ›´æ–°è·¯å¾„è®°å¿†
            path_memories = new_path_memories
            
            # æœ€ç»ˆçš„èŠ‚ç‚¹æ›´æ–° (ä½¿ç”¨æ®‹å·®è¿æ¥)
            h = self.layer_norms[layer_idx](previous_h + self.attention_output(combined_messages))
            h = self.dropout_layer(h)
            previous_h = h
        
        # åˆå¹¶èŠ‚ç‚¹ç‰¹å¾å’Œè·¯å¾„è®°å¿†
        final_repr = h + path_memories
        
        return final_repr
    
    def forward_with_attention(self, g, node_feats, edge_weights=None):
        """å‰å‘ä¼ æ’­å¹¶è¿”å›æ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºè¿‡æ‹Ÿåˆç›‘æ§"""
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹åº”ç”¨ä¸åŒçš„è½¬æ¢
        h = torch.zeros(node_feats.size(0), self.hidden_dim, device=node_feats.device)
        
        # æ ¹æ®èŠ‚ç‚¹è§’è‰²åº”ç”¨ä¸åŒçš„å˜æ¢
        for i, ntype in enumerate(g.ndata['role']):
            if ntype == 'question':
                h[i] = self.question_transform(node_feats[i])
            elif ntype in ['evidence', 'answer']:
                h[i] = self.entity_transform(node_feats[i])
            else:  # context
                h[i] = self.context_transform(node_feats[i])
        
        # åˆå§‹åŒ–ç‰¹å¾
        h = F.relu(h)
        
        # ä¿å­˜æ‰€æœ‰èŠ‚ç‚¹çš„è·¯å¾„è®°å¿†
        path_memories = h.detach().clone()
        
        # ä¿å­˜æ¯å±‚çš„èŠ‚ç‚¹è¡¨ç¤ºç”¨äºæ®‹å·®è¿æ¥
        previous_h = h
        
        # è¾¹ç¼˜æ³¨æ„åŠ›åˆ†æ•° - ç”¨äºç›‘æ§
        edge_attention_scores = {}
        
        # æ¶ˆæ¯ä¼ é€’
        for layer_idx in range(self.num_layers):
            # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
            multi_head_out = []
            
            for head_idx in range(self.num_heads):
                q_transform, k_transform, v_transform = self.attention_heads[head_idx]
                
                # è®¡ç®—æŸ¥è¯¢ã€é”®ã€å€¼
                queries = q_transform(h)
                keys = k_transform(h) 
                values = v_transform(h)
                
                # æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ (ä½¿ç”¨src-dstè¾¹ä¿¡æ¯)
                edge_src, edge_dst = g.edges()
                
                # åˆå§‹åŒ–æ¶ˆæ¯
                head_messages = torch.zeros(h.size(0), self.hidden_dim // self.num_heads, device=h.device)
                
                # å¯¹æ¯æ¡è¾¹è®¡ç®—æ³¨æ„åŠ›
                for i in range(len(edge_src)):
                    src, dst = edge_src[i], edge_dst[i]
                    
                    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
                    attn_score = torch.sum(queries[dst] * keys[src]) / np.sqrt(self.hidden_dim // self.num_heads)
                    
                    # è·å–è¾¹ç±»å‹å¹¶åº”ç”¨ç‰¹å®šå˜æ¢
                    edge_type = g.edata['rel'][i] if 'rel' in g.edata else 'default'
                    if isinstance(edge_type, torch.Tensor):
                        edge_type = 'default'
                    
                    # è·å–å¯¹åº”çš„è¾¹å˜æ¢
                    if edge_type in self.edge_transforms:
                        transform = self.edge_transforms[edge_type]
                    else:
                        transform = self.edge_transforms['default']
                    
                    # åº”ç”¨æ³¨æ„åŠ›å’Œè¾¹æƒé‡
                    edge_weight = edge_weights[i] if edge_weights is not None else 1.0
                    attn_weight = F.softmax(attn_score, dim=0) * edge_weight
                    
                    # ä¿å­˜æ³¨æ„åŠ›åˆ†æ•°ç”¨äºç›‘æ§
                    edge_key = (src.item(), dst.item())
                    if edge_key not in edge_attention_scores:
                        edge_attention_scores[edge_key] = []
                    edge_attention_scores[edge_key].append(attn_weight.item())
                    
                    # è®¡ç®—æ¶ˆæ¯
                    message = transform(values[src]) * attn_weight
                    head_messages[dst] += message
                
                multi_head_out.append(head_messages)
            
            # åˆå¹¶å¤šå¤´è¾“å‡º
            if len(multi_head_out) > 0:
                combined_messages = torch.cat(multi_head_out, dim=-1)
            else:
                combined_messages = torch.zeros(h.size(0), self.hidden_dim, device=h.device)
            
            # æ›´æ–°è·¯å¾„è®°å¿†
            new_path_memories = torch.zeros_like(path_memories)
            for i in range(len(h)):
                if combined_messages.size(-1) == self.hidden_dim:
                    new_path_memories[i] = self.path_memory(combined_messages[i], path_memories[i])
                else:
                    adjusted_input = self.attention_output(combined_messages[i])
                    new_path_memories[i] = self.path_memory(adjusted_input, path_memories[i])
            
            path_memories = new_path_memories
            
            # æœ€ç»ˆçš„èŠ‚ç‚¹æ›´æ–° (ä½¿ç”¨æ®‹å·®è¿æ¥)
            h = self.layer_norms[layer_idx](previous_h + self.attention_output(combined_messages))
            h = self.dropout_layer(h)
            previous_h = h
        
        # åˆå¹¶èŠ‚ç‚¹ç‰¹å¾å’Œè·¯å¾„è®°å¿†
        final_repr = h + path_memories
        
        return final_repr, edge_attention_scores
    
    def _extract_paths(self, g, edge_attention_scores, question_idx, max_paths=5, max_length=3):
        """æå–æœ€å¯èƒ½çš„è·¯å¾„"""
        # å»ºç«‹æœ‰å‘å›¾
        G = nx.DiGraph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for i in range(g.number_of_nodes()):
            G.add_node(i)
        
        # æ·»åŠ å¸¦æƒé‡çš„è¾¹
        edge_src, edge_dst = g.edges()
        for i in range(len(edge_src)):
            src, dst = edge_src[i].item(), edge_dst[i].item()
            edge_key = (src, dst)
            # ä½¿ç”¨å¹³å‡æ³¨æ„åŠ›åˆ†æ•°ä½œä¸ºè¾¹æƒé‡
            weight = np.mean(edge_attention_scores.get(edge_key, [0.01]))
            G.add_edge(src, dst, weight=weight)
        
        # å¯»æ‰¾ä»é—®é¢˜èŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹çš„æœ€å¯èƒ½è·¯å¾„
        if question_idx == -1 and g.number_of_nodes() > 0:
            question_idx = 0
            
        # è·¯å¾„æå–
        paths = []
        for target in range(g.number_of_nodes()):
            if target != question_idx:
                try:
                    # æ‰¾åˆ°æœ€çŸ­è·¯å¾„
                    shortest_path = nx.shortest_path(G, question_idx, target, weight='weight')
                    if len(shortest_path) <= max_length:
                        # è®¡ç®—è·¯å¾„æ€»æƒé‡
                        path_weight = sum(G[shortest_path[i]][shortest_path[i+1]]['weight'] 
                                         for i in range(len(shortest_path)-1))
                        paths.append((shortest_path, path_weight))
                except (nx.NetworkXNoPath, nx.NodeNotFound):
                    continue
        
        # æŒ‰ç…§è·¯å¾„æƒé‡æ’åº
        paths.sort(key=lambda x: x[1], reverse=True)
        return paths[:max_paths]
    
    def compute_answer_scores(self, g, node_feats, edge_weights, question_idx, candidate_idxs):
        """è®¡ç®—æ‰€æœ‰å€™é€‰ç­”æ¡ˆçš„åˆ†æ•°"""
        # è·å–æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤º
        node_embeddings = self.forward(g, node_feats, edge_weights)
        
        # è·å–é—®é¢˜èŠ‚ç‚¹çš„è¡¨ç¤º
        q_embedding = node_embeddings[question_idx]
        
        # è®¡ç®—æ¯ä¸ªå€™é€‰ç­”æ¡ˆçš„åˆ†æ•°
        scores = torch.zeros(len(candidate_idxs), device=node_feats.device)
        for i, ans_idx in enumerate(candidate_idxs):
            # è®¡ç®—é—®é¢˜å’Œç­”æ¡ˆè¡¨ç¤ºä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
            ans_embedding = node_embeddings[ans_idx]
            sim = F.cosine_similarity(q_embedding.unsqueeze(0), ans_embedding.unsqueeze(0))
            scores[i] = sim
        
        return scores
    
    def get_edge_predictions(self, g, node_feats, edge_weights):
        """é¢„æµ‹è¾¹çš„é‡è¦æ€§ï¼Œç”¨äºè®¡ç®—AUPRC"""
        # è·å–æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤º
        node_embeddings = self.forward(g, node_feats, edge_weights)
        
        # è·å–è¾¹çš„æºå’Œç›®æ ‡
        edge_src, edge_dst = g.edges()
        
        # è®¡ç®—é¢„æµ‹çš„è¾¹é‡è¦æ€§
        pred_edge_weights = torch.zeros(len(edge_src), device=node_feats.device)
        for i in range(len(edge_src)):
            src, dst = edge_src[i], edge_dst[i]
            
            # è®¡ç®—æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
            src_embed = node_embeddings[src]
            dst_embed = node_embeddings[dst]
            
            # ä½¿ç”¨ç‚¹ç§¯ä½œä¸ºç›¸ä¼¼åº¦
            sim = torch.dot(src_embed, dst_embed)
            pred_edge_weights[i] = sim
        
        return pred_edge_weights

# å›¾æ•°æ®é›†
class GraphDataset(Dataset):
    def __init__(self, graph_dir, graph_files=None, max_nodes=100):
        self.graph_dir = graph_dir
        self.max_nodes = max_nodes
        
        # åŠ è½½å›¾æ–‡ä»¶åˆ—è¡¨
        if graph_files is None:
            self.graph_files = [f for f in os.listdir(graph_dir) if f.endswith('.json')]
        else:
            self.graph_files = graph_files
        
        print(f"åŠ è½½äº† {len(self.graph_files)} ä¸ªå›¾æ–‡ä»¶")
    
    def __len__(self):
        return len(self.graph_files)
    
    def __getitem__(self, idx):
        graph_file = os.path.join(self.graph_dir, self.graph_files[idx])
        
        # åŠ è½½å›¾æ•°æ®
        with open(graph_file, 'r', encoding='utf-8') as f:
            graph_data = json.load(f)
        
        # æ„å»ºDGLå›¾
        g, node_feats, edge_weights, meta_info = self.build_graph(graph_data)
        
        return {
            'graph': g,
            'node_feats': node_feats,
            'edge_weights': edge_weights,
            'question_idx': meta_info['question_idx'],
            'answer_idx': meta_info['answer_idx'],
            'candidate_idxs': meta_info['candidate_idxs'],
            'graph_id': graph_data.get('id', self.graph_files[idx])
        }
    
    def build_graph(self, graph_data):
        """å°†JSONå›¾è½¬æ¢ä¸ºDGLå›¾"""
        nodes = graph_data.get('nodes', [])
        edges = graph_data.get('edges', [])
        
        # é™åˆ¶èŠ‚ç‚¹æ•°é‡
        if len(nodes) > self.max_nodes:
            nodes = nodes[:self.max_nodes]
        
        # åˆ›å»ºèŠ‚ç‚¹ç‰¹å¾
        node_feats = []
        node_roles = []
        
        # è®°å½•é—®é¢˜å’Œç­”æ¡ˆèŠ‚ç‚¹çš„ç´¢å¼•
        question_idx = -1
        answer_idx = -1
        candidate_idxs = []
        
        # å¤„ç†èŠ‚ç‚¹
        for i, node in enumerate(nodes):
            # èŠ‚ç‚¹ç‰¹å¾
            if 'feat' in node and node['feat'] != 'PLACEHOLDER':
                try:
                    feat = torch.tensor(node['feat'], dtype=torch.float)
                    if feat.shape[0] < 768:
                        feat = torch.cat([feat, torch.zeros(768-feat.shape[0])])
                    elif feat.shape[0] > 768:
                        feat = feat[:768]
                except:
                    feat = torch.randn(768)
            else:
                feat = torch.randn(768)
            
            node_feats.append(feat)
            
            # èŠ‚ç‚¹è§’è‰²
            role = node.get('role', 'context')
            node_roles.append(role)
            
            # è®°å½•ç‰¹æ®ŠèŠ‚ç‚¹
            if role == 'question':
                question_idx = i
            elif role == 'answer':
                answer_idx = i
                candidate_idxs.append(i)
            elif role == 'evidence':
                # è¯æ®èŠ‚ç‚¹ä¹Ÿå¯èƒ½æ˜¯å€™é€‰ç­”æ¡ˆ
                candidate_idxs.append(i)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é—®é¢˜èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
        if question_idx == -1 and len(nodes) > 0:
            question_idx = 0
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆèŠ‚ç‚¹ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªèŠ‚ç‚¹
        if answer_idx == -1 and len(nodes) > 0:
            answer_idx = len(nodes) - 1
            candidate_idxs.append(answer_idx)
        
        # å¦‚æœæ²¡æœ‰å€™é€‰ç­”æ¡ˆï¼Œä½¿ç”¨æ‰€æœ‰éé—®é¢˜èŠ‚ç‚¹
        if not candidate_idxs:
            candidate_idxs = [i for i in range(len(nodes)) if i != question_idx]
        
        # è½¬æ¢ä¸ºå¼ é‡
        node_feats = torch.stack(node_feats)
        
        # å¤„ç†è¾¹
        src_ids = []
        dst_ids = []
        edge_types = []
        edge_weights = []
        ground_truth = []  # ç”¨äºè¾¹çš„åˆ†ç±»ï¼Œæ ‡è®°é‡è¦è¾¹
        
        for edge in edges:
            src = edge.get('src', '').replace('n', '')
            dst = edge.get('dst', '').replace('n', '')
            
            # æ£€æŸ¥è¾¹çš„æœ‰æ•ˆæ€§
            if not src.isdigit() or not dst.isdigit():
                continue
            
            src_id, dst_id = int(src), int(dst)
            
            # ç¡®ä¿èŠ‚ç‚¹ç´¢å¼•æœ‰æ•ˆ
            if src_id >= len(nodes) or dst_id >= len(nodes):
                continue
            
            # æ·»åŠ è¾¹
            src_ids.append(src_id)
            dst_ids.append(dst_id)
            
            # è¾¹ç±»å‹
            rel = edge.get('rel', 'default')
            edge_types.append(rel)
            
            # è¾¹æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
            weight = edge.get('weight', 1.0)
            edge_weights.append(weight)
            
            # æ ‡è®°é‡è¦è¾¹ï¼ˆè¿æ¥ç­”æ¡ˆèŠ‚ç‚¹æˆ–è¯æ®èŠ‚ç‚¹çš„è¾¹ï¼‰
            is_important = (src_id == answer_idx) or (dst_id == answer_idx) or \
                           (nodes[src_id].get('role') == 'evidence') or \
                           (nodes[dst_id].get('role') == 'evidence')
            ground_truth.append(float(is_important))
        
        # åˆ›å»ºDGLå›¾
        g = dgl.graph((src_ids, dst_ids), num_nodes=len(nodes))
        
        # æ ¹æ®å®é™…æ·»åŠ åˆ°å›¾ä¸­çš„èŠ‚ç‚¹è¿‡æ»¤node_roles
        valid_node_indices = set(range(g.number_of_nodes()))
        filtered_node_roles = [node_roles[i] for i in valid_node_indices]
        
        # å°†è§’è‰²æ˜ å°„ä¸ºæ•°å€¼
        role_map = {'question': 0, 'context': 1, 'answer': 2, 'evidence': 3, 'distractor': 4}
        numeric_roles = [role_map.get(role, 0) for role in filtered_node_roles] 
        g.ndata['role'] = torch.tensor(numeric_roles)
        
        # è¾¹ç±»å‹è½¬ä¸ºæ•°å­—ID
        if edge_types:
            edge_type_set = list(sorted(set(edge_types)))
            edge_type_map = {etype: idx for idx, etype in enumerate(edge_type_set)}
            numeric_edge_types = [edge_type_map[etype] for etype in edge_types]
            g.edata['rel'] = torch.tensor(numeric_edge_types, dtype=torch.long)
        
        if edge_weights:
            edge_weights = torch.tensor(edge_weights, dtype=torch.float)
        else:
            edge_weights = torch.ones(g.number_of_edges(), dtype=torch.float)
        
        # æ·»åŠ è¾¹çš„ground truth (ç”¨äºè®¡ç®—AUPRC)
        g.edata['ground_truth'] = torch.tensor(ground_truth, dtype=torch.float)
        
        # å…ƒä¿¡æ¯
        meta_info = {
            'question_idx': question_idx,
            'answer_idx': answer_idx,
            'candidate_idxs': candidate_idxs
        }
        
        return g, node_feats, edge_weights, meta_info

def collate_fn(samples):
    graphs = [s['graph'] for s in samples]
    
    # æ£€æŸ¥å›¾æ˜¯å¦ä¸ºå¼‚æ„å›¾
    is_hetero = False
    if graphs and hasattr(graphs[0], 'ntypes') and len(graphs[0].ntypes) > 1:
        is_hetero = True
    
    if is_hetero:
        # å¯¹äºå¼‚æ„å›¾ï¼Œä¸ä½¿ç”¨batchæ“ä½œï¼Œç›´æ¥ä¿å­˜å›¾åˆ—è¡¨
        batched_graphs = graphs
    else:
        # å¯¹äºåŒæ„å›¾ï¼Œä½¿ç”¨dgl.batch
        batched_graphs = dgl.batch(graphs)
        
    node_feats = torch.cat([s['node_feats'] for s in samples], dim=0)
    edge_weights = torch.cat([s['edge_weights'] for s in samples], dim=0)
    question_idx = torch.tensor([s['question_idx'] for s in samples], dtype=torch.long)
    answer_idx = torch.tensor([s['answer_idx'] for s in samples], dtype=torch.long)
    candidate_idxs = [s['candidate_idxs'] for s in samples]
    graph_id = [s['graph_id'] for s in samples]
    
    return {
        'graph': batched_graphs,
        'node_feats': node_feats,
        'edge_weights': edge_weights,
        'question_idx': question_idx,
        'answer_idx': answer_idx,
        'candidate_idxs': candidate_idxs,
        'graph_id': graph_id
    }

def calculate_node_recall_at_k(model, data_loader, device, k=20):
    """è®¡ç®—Node Recall@kæŒ‡æ ‡"""
    model.eval()
    total_recall = 0.0
    count = 0
    
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="è®¡ç®—Node Recall@k"):
            g = batch['graph'].to(device)
            node_feats = batch['node_feats'].to(device)
            edge_weights = batch['edge_weights'].to(device)
            question_idx = batch['question_idx'].to(device)
            answer_idx = batch['answer_idx'].to(device)
            
            # è·å–æ‰¹é‡å¤§å° - é¿å…ä½¿ç”¨len(g)
            batch_size = g.batch_size if hasattr(g, 'batch_size') else len(batch['question_idx'])
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ„å›¾
            is_hetero = hasattr(g, 'ntypes') and len(g.ntypes) > 1
            
            # å¤„ç†æ¯ä¸ªæ ·æœ¬
            for i in range(batch_size):
                # è·å–å½“å‰å›¾å’Œç‰¹å¾
                if is_hetero:
                    current_g = g[i] if isinstance(g, list) else g
                    current_feats = node_feats[i]
                    current_weights = edge_weights[i] if edge_weights.dim() > 1 else edge_weights
                    q_idx = question_idx[i]
                    a_idx = answer_idx[i]
                else:
                    # å¯¹äºåŒæ„å›¾ï¼Œä½¿ç”¨æ‰¹å¤„ç†ç´¢å¼•
                    current_g = g
                    current_feats = node_feats
                    current_weights = edge_weights
                    q_idx = question_idx[i]
                    a_idx = answer_idx[i]
                
                # è·å–èŠ‚ç‚¹åµŒå…¥
                node_embeddings = model.forward(current_g, current_feats, current_weights)
                
                # è·å–é—®é¢˜èŠ‚ç‚¹åµŒå…¥
                q_embedding = node_embeddings[q_idx]
                
                # è®¡ç®—é—®é¢˜èŠ‚ç‚¹ä¸æ‰€æœ‰èŠ‚ç‚¹çš„ç›¸ä¼¼åº¦
                similarities = []
                q_idx_scalar = q_idx.item()  # è½¬ä¸ºæ ‡é‡ç”¨äºæ¯”è¾ƒ
                for j in range(len(node_embeddings)):
                    if j != q_idx_scalar:  # æ’é™¤é—®é¢˜èŠ‚ç‚¹è‡ªèº«
                        sim = F.cosine_similarity(q_embedding.unsqueeze(0), node_embeddings[j].unsqueeze(0))
                        similarities.append((j, sim))
                
                # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶å–top-k
                similarities.sort(key=lambda x: x[1], reverse=True)
                top_k_nodes = [item[0] for item in similarities[:k]]
                
                # æ£€æŸ¥ç­”æ¡ˆèŠ‚ç‚¹æ˜¯å¦åœ¨top-kä¸­
                a_idx_scalar = a_idx.item()  # è½¬ä¸ºæ ‡é‡ç”¨äºæ¯”è¾ƒ
                if a_idx_scalar in top_k_nodes:
                    total_recall += 1
                
                count += 1
    
    return total_recall / count if count > 0 else 0


def calculate_auprc(model, data_loader, device):
    """è®¡ç®—è¾¹åˆ†ç±»çš„AUPRC"""
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in data_loader:
            g = batch['graph'].to(device)
            node_feats = batch['node_feats'].to(device)
            edge_weights = batch['edge_weights'].to(device)
            
            # è·å–è¾¹çš„é¢„æµ‹æƒé‡
            pred_weights = model.get_edge_predictions(g, node_feats, edge_weights)
            
            # è·å–è¾¹çš„çœŸå®æ ‡ç­¾
            true_labels = g.edata['ground_truth']
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
            all_preds.extend(pred_weights.cpu().numpy())
            all_labels.extend(true_labels.cpu().numpy())
    
    # è®¡ç®—PRæ›²çº¿å’ŒAUPRC
    precision, recall, _ = precision_recall_curve(all_labels, all_preds)
    auprc = auc(recall, precision)
    
    return auprc, precision, recall

def train(model, train_loader, optimizer, device, epoch, writer):
    """è®­ç»ƒæ¨¡å‹ä¸€ä¸ªepochå¹¶è¿”å›æŸå¤±å’ŒæŒ‡æ ‡"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader),
                       desc=f"Epoch {epoch+1}", leave=True)
    
    for batch_idx, batch in progress_bar:
        g = batch['graph'].to(device)
        node_feats = batch['node_feats'].to(device)
        edge_weights = batch['edge_weights'].to(device)
        question_idx = batch['question_idx'].to(device)
        answer_idx = batch['answer_idx'].to(device)
        candidate_idxs = batch['candidate_idxs']
        
        # æ¸…ç©ºæ¢¯åº¦
        optimizer.zero_grad()
        
        # æ„å»ºå€™é€‰ç­”æ¡ˆçš„ä¸€ç»´å¼ é‡
        candidate_tensor = []
        for candidates in candidate_idxs:
            candidate_tensor.extend(candidates)
        candidate_tensor = torch.tensor(candidate_tensor, device=device)
        
        # è®¡ç®—å€™é€‰ç­”æ¡ˆçš„åˆ†æ•°
        batch_scores = []
        batch_labels = []
        
        # è·å–æ‰¹é‡å¤§å° - é¿å…ä½¿ç”¨len(g)
        batch_size = g.batch_size if hasattr(g, 'batch_size') else len(candidate_idxs)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ„å›¾
        is_hetero = hasattr(g, 'ntypes') and len(g.ntypes) > 1
        
        for i in range(batch_size):
            # è·å–å½“å‰å›¾çš„å€™é€‰ç­”æ¡ˆç´¢å¼•
            candidates = candidate_idxs[i]
            
            # è®¡ç®—æ¯ä¸ªå€™é€‰ç­”æ¡ˆçš„åˆ†æ•°
            if is_hetero:
                # å¯¹äºå¼‚æ„å›¾ï¼Œæˆ‘ä»¬éœ€è¦å•ç‹¬å¤„ç†æ¯ä¸ªå›¾
                current_g = g[i] if isinstance(g, list) else g
                current_feats = node_feats[i]
                current_weights = edge_weights[i] if edge_weights.dim() > 1 else edge_weights
                current_q_idx = question_idx[i]
            else:
                # å¯¹äºåŒæ„å›¾ï¼Œä½¿ç”¨æ‰¹å¤„ç†ç´¢å¼•
                current_g = g
                current_feats = node_feats
                current_weights = edge_weights
                current_q_idx = question_idx[i]
            
            scores = model.compute_answer_scores(
                current_g, current_feats, current_weights, 
                current_q_idx, candidates
            )
            
            # åˆ›å»ºæ ‡ç­¾ï¼Œæ­£ç¡®çš„ç­”æ¡ˆæ ‡è®°ä¸º1ï¼Œå…¶ä»–æ ‡è®°ä¸º0
            labels = torch.zeros_like(scores)
            for j, c_idx in enumerate(candidates):
                if c_idx == answer_idx[i].item():
                    labels[j] = 1
                    break
            
            batch_scores.append(scores)
            batch_labels.append(labels)
        
        # è®¡ç®—æŸå¤±
        scores = torch.cat(batch_scores)
        labels = torch.cat(batch_labels)
        
        # ä½¿ç”¨BCE loss
        loss = F.binary_cross_entropy_with_logits(scores, labels)
        
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        total_loss += loss.item()
        
        # è®¡ç®—å‡†ç¡®ç‡
        pred = (scores > 0.5).float()
        current_correct = (pred == labels).sum().item()
        correct += current_correct
        current_total = len(scores)
        total += current_total
        
        # è®°å½•Lossåˆ°TensorBoard
        writer.add_scalar('Training/Loss', loss.item(), epoch * len(train_loader) + batch_idx)
        
        # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
        progress_bar.set_postfix({
            'loss': f"{loss.item():.4f}",
            'acc': f"{current_correct/current_total:.4f}" if current_total > 0 else "N/A"
        })
    
    # è®¡ç®—è¾¹åˆ†ç±»çš„AUPRC
    print("è®¡ç®—è®­ç»ƒé›†AUPRC...")
    auprc, precision, recall = calculate_auprc(model, train_loader, device)
    
    # è®¡ç®—Node Recall@20
    print("è®¡ç®—è®­ç»ƒé›†Node Recall@20...")
    node_recall = calculate_node_recall_at_k(model, train_loader, device, k=20)
    
    # ç»˜åˆ¶PRæ›²çº¿å¹¶ä¿å­˜
    plt.figure(figsize=(10, 8))
    plt.plot(recall, precision, label=f'AUPRC = {auprc:.3f}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(f'Precision-Recall Curve (Epoch {epoch})')
    plt.legend()
    
    # ä¿å­˜PRæ›²çº¿åˆ°TensorBoard
    writer.add_figure('Training/PR_Curve', plt.gcf(), epoch)
    
    # è®°å½•AUPRCå’ŒNode Recallåˆ°TensorBoard
    writer.add_scalar('Training/AUPRC', auprc, epoch)
    writer.add_scalar('Training/NodeRecall@20', node_recall, epoch)
    
    avg_loss = total_loss / len(train_loader)
    accuracy = correct / total if total > 0 else 0
    
    writer.add_scalar('Training/Accuracy', accuracy, epoch)
    
    print(f"è®­ç»ƒ: Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}, AUPRC: {auprc:.4f}, Recall@20: {node_recall:.4f}")
    
    return avg_loss, accuracy, auprc, node_recall

def validate(model, val_loader, device, epoch, writer):
    """éªŒè¯æ¨¡å‹å¹¶è¿”å›æŸå¤±å’ŒæŒ‡æ ‡"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        progress_bar = tqdm(val_loader, desc="éªŒè¯", leave=False)
        for batch in progress_bar:
            g = batch['graph'].to(device)
            node_feats = batch['node_feats'].to(device)
            edge_weights = batch['edge_weights'].to(device)
            question_idx = batch['question_idx'].to(device)
            answer_idx = batch['answer_idx'].to(device)
            candidate_idxs = batch['candidate_idxs']
            
            # è®¡ç®—å€™é€‰ç­”æ¡ˆçš„åˆ†æ•°
            batch_scores = []
            batch_labels = []
            
            # è·å–æ‰¹é‡å¤§å° - é¿å…ä½¿ç”¨len(g)
            batch_size = g.batch_size if hasattr(g, 'batch_size') else len(candidate_idxs)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ„å›¾
            is_hetero = hasattr(g, 'ntypes') and len(g.ntypes) > 1
            
            for i in range(batch_size):
                # è·å–å½“å‰å›¾çš„å€™é€‰ç­”æ¡ˆç´¢å¼•
                candidates = candidate_idxs[i]
                
                # è®¡ç®—æ¯ä¸ªå€™é€‰ç­”æ¡ˆçš„åˆ†æ•°
                if is_hetero:
                    # å¯¹äºå¼‚æ„å›¾ï¼Œæˆ‘ä»¬éœ€è¦å•ç‹¬å¤„ç†æ¯ä¸ªå›¾
                    current_g = g[i] if isinstance(g, list) else g
                    current_feats = node_feats[i]
                    current_weights = edge_weights[i] if edge_weights.dim() > 1 else edge_weights
                    current_q_idx = question_idx[i]
                else:
                    # å¯¹äºåŒæ„å›¾ï¼Œä½¿ç”¨æ‰¹å¤„ç†ç´¢å¼•
                    current_g = g
                    current_feats = node_feats
                    current_weights = edge_weights
                    current_q_idx = question_idx[i]
                
                scores = model.compute_answer_scores(
                    current_g, current_feats, current_weights, 
                    current_q_idx, candidates
                )
                
                # åˆ›å»ºæ ‡ç­¾ï¼Œæ­£ç¡®çš„ç­”æ¡ˆæ ‡è®°ä¸º1ï¼Œå…¶ä»–æ ‡è®°ä¸º0
                labels = torch.zeros_like(scores)
                for j, c_idx in enumerate(candidates):
                    if c_idx == answer_idx[i].item():
                        labels[j] = 1
                        break
                
                batch_scores.append(scores)
                batch_labels.append(labels)
            
            # è®¡ç®—æŸå¤±
            scores = torch.cat(batch_scores)
            labels = torch.cat(batch_labels)
            
            # ä½¿ç”¨BCE loss
            loss = F.binary_cross_entropy_with_logits(scores, labels)
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            
            # è®¡ç®—å‡†ç¡®ç‡
            pred = (scores > 0.5).float()
            correct += (pred == labels).sum().item()
            total += len(scores)
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
            all_preds.extend(scores.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({'loss': f"{loss.item():.4f}"})
    
    # è®¡ç®—è¾¹åˆ†ç±»çš„AUPRCå’ŒPRæ›²çº¿
    print("è®¡ç®—éªŒè¯é›†AUPRC...")
    auprc, precision, recall = calculate_auprc(model, val_loader, device)
    
    # è®¡ç®—Node Recall@20
    print("è®¡ç®—éªŒè¯é›†Node Recall@20...")
    node_recall = calculate_node_recall_at_k(model, val_loader, device, k=20)
    
    # ç»˜åˆ¶éªŒè¯é›†çš„PRæ›²çº¿
    plt.figure(figsize=(10, 8))
    plt.plot(recall, precision, label=f'AUPRC = {auprc:.3f}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(f'Validation Precision-Recall Curve (Epoch {epoch})')
    plt.legend()
    
    # ä¿å­˜PRæ›²çº¿åˆ°TensorBoard
    writer.add_figure('Validation/PR_Curve', plt.gcf(), epoch)
    
    # è®°å½•éªŒè¯é›†æŒ‡æ ‡åˆ°TensorBoard
    writer.add_scalar('Validation/Loss', total_loss / len(val_loader), epoch)
    writer.add_scalar('Validation/AUPRC', auprc, epoch)
    writer.add_scalar('Validation/NodeRecall@20', node_recall, epoch)
    
    avg_loss = total_loss / len(val_loader)
    accuracy = correct / total if total > 0 else 0
    
    writer.add_scalar('Validation/Accuracy', accuracy, epoch)
    writer.add_scalar('Validation/F1', 2 * (auprc * node_recall) / (auprc + node_recall) if auprc + node_recall > 0 else 0, epoch)
    
    print(f"éªŒè¯: Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}, AUPRC: {auprc:.4f}, Recall@20: {node_recall:.4f}")
    
    return avg_loss, accuracy, auprc, node_recall

def check_early_stopping(auprc_history, recall_history, em_f1_history, patience=5, threshold_auprc=0.30, threshold_recall=0.90):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
    # å¦‚æœå†å²è®°å½•ä¸è¶³ï¼Œä¸èƒ½æ—©åœ
    if len(auprc_history) < patience or len(recall_history) < patience or len(em_f1_history) < patience:
        return False
    
    # æ¡ä»¶1: AUPRC >= 0.30 ä¸” Recall >= 0.90
    if auprc_history[-1] >= threshold_auprc and recall_history[-1] >= threshold_recall:
        return True
    
    # æ¡ä»¶2: æœ€è¿‘5ä¸ªepochä¸‰ä¸ªæŒ‡æ ‡å‡å¢å¹… < 0.1pp
    recent_auprc = list(auprc_history)[-patience:]
    recent_recall = list(recall_history)[-patience:]
    recent_em_f1 = list(em_f1_history)[-patience:]
    
    auprc_improved = max(recent_auprc) - min(recent_auprc) < 0.001
    recall_improved = max(recent_recall) - min(recent_recall) < 0.001
    em_f1_improved = max(recent_em_f1) - min(recent_em_f1) < 0.001
    
    return auprc_improved and recall_improved and em_f1_improved

def main():
    parser = argparse.ArgumentParser(description='çº¯GNNå¤šè·³æ¨ç†è®­ç»ƒ')
    parser.add_argument('--graph_dir', type=str, required=True, help='å›¾æ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--hidden_dim', type=int, default=256, help='éšè—å±‚ç»´åº¦')
    parser.add_argument('--num_layers', type=int, default=6, help='GNNå±‚æ•° (6-8)')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤§å°')
    parser.add_argument('--lr', type=float, default=0.001, help='å­¦ä¹ ç‡')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--dropout', type=float, default=0.2, help='Dropoutç‡')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--cuda', action='store_true', help='ä½¿ç”¨CUDA')
    parser.add_argument('--checkpoint', type=str, default=None, help='åŠ è½½æ£€æŸ¥ç‚¹')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•å’Œæ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    checkpoint_dir = os.path.join(args.output_dir, 'checkpoints')
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # è®¾ç½®TensorBoard
    log_dir = os.path.join(args.output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    writer = SummaryWriter(log_dir=log_dir)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if args.cuda and torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    all_files = [f for f in os.listdir(args.graph_dir) if f.endswith('.json')]
    random.shuffle(all_files)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    split = int(0.8 * len(all_files))
    train_files = all_files[:split]
    val_files = all_files[split:]
    
    train_dataset = GraphDataset(args.graph_dir, train_files)
    val_dataset = GraphDataset(args.graph_dir, val_files)
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, collate_fn=collate_fn)
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}, éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = PathAttentionGNN(in_dim=768, hidden_dim=args.hidden_dim, num_layers=args.num_layers, num_heads=4, dropout=args.dropout)
    model.to(device)
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    
    # åˆ›å»ºè¿‡æ‹Ÿåˆç›‘æ§å™¨
    overfitting_monitor = Route0OverfittingMonitor(patience=5, min_delta=0.001)
    
    # åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
    start_epoch = 0
    if args.checkpoint and os.path.exists(args.checkpoint):
        checkpoint = torch.load(args.checkpoint)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"ä»epoch {start_epoch}æ¢å¤è®­ç»ƒ...")
    
    # è®­ç»ƒå¾ªç¯
    print("å¼€å§‹è®­ç»ƒ...")
    best_val_auprc = 0
    patience_counter = 0
    
    # å†å²æŒ‡æ ‡è®°å½•ç”¨äºæ—©åœ
    auprc_history = deque(maxlen=10)
    recall_history = deque(maxlen=10)
    em_f1_history = deque(maxlen=10)
    
    for epoch in range(start_epoch, args.epochs):
        # è®­ç»ƒ
        train_loss, train_acc, train_auprc, train_recall = train(model, train_loader, optimizer, device, epoch, writer)
        
        # éªŒè¯
        val_loss, val_acc, val_auprc, val_recall = validate(model, val_loader, device, epoch, writer)
        
        # è®¡ç®—EM/F1 (ç®€åŒ–ç‰ˆï¼Œè¿™é‡Œç”¨val_accä»£æ›¿)
        val_em_f1 = val_acc
        
        # è·å–æ³¨æ„åŠ›æƒé‡ç”¨äºè¿‡æ‹Ÿåˆç›‘æ§
        attention_weights = None
        sample_g = None
        sample_feats = None
        sample_weights = None
        sample_q_idx = None
        
        try:
            # ä»éªŒè¯é›†è·å–ä¸€ä¸ªæ ·æœ¬ç”¨äºæ³¨æ„åŠ›åˆ†æ
            for batch in val_loader:
                sample_g = batch['graph'].to(device)
                sample_feats = batch['node_feats'].to(device)
                sample_weights = batch['edge_weights'].to(device)
                sample_q_idx = batch['question_idx'][0].item() if len(batch['question_idx']) > 0 else 0
                
                # è·å–æ³¨æ„åŠ›æƒé‡
                with torch.no_grad():
                    _, attention_weights = model.forward_with_attention(sample_g, sample_feats, sample_weights)
                break
        except Exception as e:
            print(f"è·å–æ³¨æ„åŠ›æƒé‡æ—¶å‡ºé”™: {e}")
            attention_weights = None
        
        # æ›´æ–°è¿‡æ‹Ÿåˆç›‘æ§å™¨
        overfitting_monitor.update(
            train_loss=train_loss,
            val_loss=val_loss,
            train_acc=train_acc,
            val_acc=val_acc,
            attention_weights=attention_weights,
            model=model,
            g=sample_g,
            node_feats=sample_feats,
            edge_weights=sample_weights,
            question_idx=sample_q_idx
        )
        
        # ç”Ÿæˆè¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Š
        print("\n" + overfitting_monitor.get_report())
        
        # ä¿å­˜è¿‡æ‹Ÿåˆåˆ†æå›¾è¡¨
        analysis_plot_path = os.path.join(args.output_dir, f'overfitting_analysis_epoch_{epoch}.png')
        overfitting_monitor.plot_analysis(save_path=analysis_plot_path)
        
        # æ›´æ–°å†å²æŒ‡æ ‡
        auprc_history.append(val_auprc)
        recall_history.append(val_recall)
        em_f1_history.append(val_em_f1)
        
        print(f"Epoch {epoch}:")
        print(f"  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, AUPRC: {train_auprc:.4f}, Recall@20: {train_recall:.4f}")
        print(f"  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUPRC: {val_auprc:.4f}, Recall@20: {val_recall:.4f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': train_loss,
            'val_loss': val_loss,
            'val_auprc': val_auprc,
            'val_recall': val_recall,
        }, checkpoint_path)
        
        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜ä¸ºbest_model.pt
        if val_auprc > best_val_auprc:
            best_val_auprc = val_auprc
            best_model_path = os.path.join(args.output_dir, 'best_model.pt')
            torch.save(model.state_dict(), best_model_path)
            print(f"  ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒAUPRC: {val_auprc:.4f}")
            patience_counter = 0
        else:
            patience_counter += 1
        
        # æ£€æŸ¥è¿‡æ‹Ÿåˆç›‘æ§å™¨çš„æ—©åœå»ºè®®
        if overfitting_monitor.should_early_stop():
            print(f"è¿‡æ‹Ÿåˆç›‘æ§å™¨å»ºè®®æ—©åœï¼Œåœæ­¢è®­ç»ƒã€‚")
            break
        
        # æ£€æŸ¥æ—©åœæ¡ä»¶
        if check_early_stopping(auprc_history, recall_history, em_f1_history):
            print(f"è§¦å‘æ—©åœæ¡ä»¶ï¼Œåœæ­¢è®­ç»ƒã€‚")
            break
        
        # è¶…è¿‡10è½®æ²¡æœ‰æ”¹è¿›ï¼Œè¿›è¡Œæ—©åœ
        if patience_counter >= 10:
            print(f"è¶…è¿‡10è½®æ— æ”¹è¿›ï¼Œåœæ­¢è®­ç»ƒã€‚")
            break
    
    # ç”Ÿæˆæœ€ç»ˆçš„è¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Š
    final_analysis_path = os.path.join(args.output_dir, 'final_overfitting_analysis.png')
    overfitting_monitor.plot_analysis(save_path=final_analysis_path)
    
    # ä¿å­˜æœ€ç»ˆåˆ†ææŠ¥å‘Š
    final_report_path = os.path.join(args.output_dir, 'final_overfitting_report.txt')
    with open(final_report_path, 'w', encoding='utf-8') as f:
        f.write(overfitting_monitor.get_report())
    
    print(f"\næœ€ç»ˆè¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {final_report_path}")
    print(f"æœ€ç»ˆè¿‡æ‹Ÿåˆåˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {final_analysis_path}")
    
    # å…³é—­TensorBoard writer
    writer.close()
    
    print("è®­ç»ƒå®Œæˆï¼")

if __name__ == "__main__":
    main() 